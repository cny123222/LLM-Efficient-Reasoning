# ğŸ¯ å¦‚ä½•åšçœŸæ­£çš„æ¶ˆèå®éªŒï¼ˆåŸºäºä¸»å®éªŒï¼‰

## ğŸ“‹ **ä»€ä¹ˆæ˜¯çœŸæ­£çš„æ¶ˆèå®éªŒï¼Ÿ**

**Ablation Study (æ¶ˆèå®éªŒ)** çš„å®šä¹‰ï¼š
- é€æ­¥**ç§»é™¤æˆ–æ·»åŠ **ç³»ç»Ÿçš„**ç»„ä»¶**
- è¯æ˜**æ¯ä¸ªç»„ä»¶**çš„**ç‹¬ç«‹è´¡çŒ®**
- å±•ç¤ºä»ç®€å•ç³»ç»Ÿåˆ°å¤æ‚ç³»ç»Ÿçš„**æ¸è¿›å¼æ”¹è¿›**

---

## âœ… **æ­£ç¡®çš„æ¶ˆèå®éªŒè®¾è®¡ï¼ˆåŸºäºä½ çš„ä¸»å®éªŒï¼‰**

### **æ–¹æ¡ˆ A: Forward Ablation (é€æ­¥æ·»åŠ ç»„ä»¶)** â­ æ¨è

```
1. Baseline (AR only)
   - çº¯è‡ªå›å½’ç”Ÿæˆï¼Œä¸ä½¿ç”¨ä»»ä½•åŠ é€ŸæŠ€æœ¯
   - Config: æ— 
   - Throughput: 127.9 t/s (1.00Ã—)
   - æ¥æº: å·²æœ‰æ•°æ® âœ…

2. + Draft Model (Linear Speculative Decoding)
   - æ·»åŠ  draft model + speculative verification
   - Config: Linear K=6
   - Throughput: 174.2 t/s (1.36Ã—)
   - è´¡çŒ®: +36.2%
   - æ¥æº: å·²æœ‰æ•°æ® âœ…

3. + Multi-path Exploration (Tree Structure)
   - æ·»åŠ æ ‘å½¢ç»“æ„ï¼Œparallel path verification
   - Config: Tree D=7, B=2, t=1.0 (no pruning)
   - Throughput: ??? t/s (éœ€è¦è·‘å®éªŒ) âŒ
   - è´¡çŒ®: ???
   
4. + Adaptive Pruning (Full DynaTree)
   - æ·»åŠ æ¦‚ç‡é˜ˆå€¼å‰ªæ
   - Config: Tree D=7, B=2, t=0.05
   - Throughput: 196.4 t/s (1.54Ã—)
   - è´¡çŒ®: ???
   - æ¥æº: å·²æœ‰æ•°æ® âœ…
```

**éœ€è¦è¡¥å……çš„å®éªŒ**:
- âœ… æ­¥éª¤ 1, 2, 4: å·²æœ‰æ•°æ®
- âŒ æ­¥éª¤ 3: éœ€è¦è·‘ **Tree without pruning** (t=1.0)

---

### **æ–¹æ¡ˆ B: Backward Ablation (é€æ­¥ç§»é™¤ç»„ä»¶)** 

```
1. Full DynaTree
   - Config: Tree D=7, B=2, t=0.05
   - Throughput: 196.4 t/s (1.54Ã—)
   - æ¥æº: å·²æœ‰æ•°æ® âœ…

2. - Adaptive Pruning (remove pruning)
   - Config: Tree D=7, B=2, t=1.0 (no threshold)
   - Throughput: ??? t/s (éœ€è¦è·‘å®éªŒ) âŒ
   - æ€§èƒ½æŸå¤±: ???

3. - Multi-path (single branch = degrade to linear)
   - Config: Tree D=7, B=1, t=0.05
   - Throughput: ~174 t/s (é¢„æœŸæ¥è¿‘ Linear)
   - æ€§èƒ½æŸå¤±: ???
   - æ¥æº: éœ€è¦è·‘å®éªŒ âŒ

4. - Draft Model (pure AR)
   - Config: çº¯è‡ªå›å½’
   - Throughput: 127.9 t/s (1.00Ã—)
   - æ¥æº: å·²æœ‰æ•°æ® âœ…
```

**éœ€è¦è¡¥å……çš„å®éªŒ**:
- âŒ æ­¥éª¤ 2: Tree D=7, B=2, t=1.0
- âŒ æ­¥éª¤ 3: Tree D=7, B=1, t=0.05

---

## ğŸ”¬ **éœ€è¦è·‘çš„å®éªŒï¼ˆæ€»å…±2-3ä¸ªé…ç½®ï¼‰**

### **å®éªŒ 1: Tree without Pruning** ğŸ”´ å¿…éœ€

**ç›®çš„**: è¯æ˜ adaptive pruning çš„è´¡çŒ®

**é…ç½®**:
```python
tree_depth = 7
branch_factor = 2
probability_threshold = 1.0  # ä¸å‰ªæï¼Œä¿ç•™æ‰€æœ‰åˆ†æ”¯
max_tree_nodes = 256  # å¯èƒ½éœ€è¦æ›´å¤§
```

**é¢„æœŸ**:
- ååé‡ä¼š**é™ä½**ï¼ˆå› ä¸ºæ ‘å¤ªå¤§ï¼ŒéªŒè¯å¼€é”€è¿‡å¤§ï¼‰
- å¯èƒ½åœ¨ 150-170 t/s ä¹‹é—´
- è¯æ˜å‰ªæçš„ä»·å€¼

**è¿è¡Œå‘½ä»¤**:
```bash
cd /root/LLM-Efficient-Reasoning
python papers/run_single_config.py \
  --depth 7 \
  --branch 2 \
  --threshold 1.0 \
  --tokens 500
```

**é¢„è®¡æ—¶é—´**: 5 åˆ†é’Ÿ

---

### **å®éªŒ 2: Tree with Single Branch (B=1)** ğŸŸ¡ å¯é€‰ä½†æ¨è

**ç›®çš„**: è¯æ˜ multi-path exploration çš„è´¡çŒ®

**é…ç½®**:
```python
tree_depth = 7
branch_factor = 1  # å•åˆ†æ”¯ = é€€åŒ–ä¸ºçº¿æ€§
probability_threshold = 0.05
```

**é¢„æœŸ**:
- ååé‡åº”è¯¥æ¥è¿‘ Linear K=7 (çº¦ 176 t/s)
- è¯æ˜å¤šè·¯å¾„æ¢ç´¢çš„ä»·å€¼

**è¿è¡Œå‘½ä»¤**:
```bash
cd /root/LLM-Efficient-Reasoning
python papers/run_single_config.py \
  --depth 7 \
  --branch 1 \
  --threshold 0.05 \
  --tokens 500
```

**é¢„è®¡æ—¶é—´**: 5 åˆ†é’Ÿ

---

### **å®éªŒ 3: Tree without Depth (D=1)** ğŸŸ¡ å¯é€‰

**ç›®çš„**: è¯æ˜ tree depth çš„è´¡çŒ®

**é…ç½®**:
```python
tree_depth = 1  # åªæœ‰ä¸€å±‚ï¼Œé€€åŒ–ä¸º greedy sampling
branch_factor = 2
probability_threshold = 0.05
```

**é¢„æœŸ**:
- ååé‡ä¼šå¾ˆä½ï¼Œæ¥è¿‘ Baseline
- è¯æ˜æ·±åº¦æ¢ç´¢çš„ä»·å€¼

**é¢„è®¡æ—¶é—´**: 5 åˆ†é’Ÿ

---

## ğŸ“ **å®éªŒè„šæœ¬ç¤ºä¾‹**

åˆ›å»º `papers/run_ablation_study.py`:

```python
#!/usr/bin/env python3
"""
Run ablation study experiments
Tests individual components of DynaTree
"""

import torch
import time
from transformers import AutoTokenizer, AutoModelForCausalLM
from spec_decode.core.tree_speculative_generator import TreeSpeculativeGeneratorV2

def load_models():
    """Load target and draft models"""
    target_model = AutoModelForCausalLM.from_pretrained(
        "/mnt/disk1/models/pythia-2.8b",
        torch_dtype=torch.float16,
        device_map="cuda"
    )
    draft_model = AutoModelForCausalLM.from_pretrained(
        "/mnt/disk1/models/pythia-70m",
        torch_dtype=torch.float16,
        device_map="cuda"
    )
    tokenizer = AutoTokenizer.from_pretrained("/mnt/disk1/models/pythia-2.8b")
    return target_model, draft_model, tokenizer

def run_config(target_model, draft_model, tokenizer, 
               depth, branch, threshold, tokens=500, runs=5):
    """Run a single configuration"""
    
    # Test prompt
    prompt = "Write a detailed explanation about speculative decoding..."
    
    results = []
    for i in range(runs):
        # Create generator
        gen = TreeSpeculativeGeneratorV2(
            target_model=target_model,
            draft_model=draft_model,
            tokenizer=tokenizer,
            tree_depth=depth,
            branch_factor=branch,
            probability_threshold=threshold,
            max_tree_nodes=256
        )
        
        # Generate
        torch.cuda.synchronize()
        start = time.perf_counter()
        
        output = gen.generate(
            prompt=prompt,
            max_new_tokens=tokens,
            temperature=0.0
        )
        
        torch.cuda.synchronize()
        elapsed = time.perf_counter() - start
        
        throughput = tokens / elapsed
        
        if i > 0:  # Skip first run (warmup)
            results.append(throughput)
        
        # Cleanup
        del gen
        torch.cuda.empty_cache()
    
    avg_throughput = sum(results) / len(results)
    return avg_throughput

def main():
    print("="*80)
    print("DynaTree Ablation Study")
    print("="*80)
    
    target_model, draft_model, tokenizer = load_models()
    
    # Baseline (AR)
    print("\n1. Baseline (AR only)")
    print("   Skipping - use existing data: 127.9 t/s")
    baseline = 127.9
    
    # Linear Speculative
    print("\n2. + Draft Model (Linear Speculative)")
    print("   Skipping - use existing data: 174.2 t/s")
    linear = 174.2
    
    # Tree without pruning
    print("\n3. + Multi-path (Tree without pruning)")
    print("   Running: D=7, B=2, t=1.0 (no pruning)...")
    tree_no_prune = run_config(
        target_model, draft_model, tokenizer,
        depth=7, branch=2, threshold=1.0, tokens=500
    )
    print(f"   Result: {tree_no_prune:.1f} t/s ({tree_no_prune/baseline:.2f}Ã—)")
    
    # Full DynaTree
    print("\n4. + Adaptive Pruning (Full DynaTree)")
    print("   Skipping - use existing data: 196.4 t/s")
    full = 196.4
    
    # Summary
    print("\n" + "="*80)
    print("Ablation Study Results")
    print("="*80)
    print(f"1. Baseline (AR):              {baseline:.1f} t/s (1.00Ã—)")
    print(f"2. + Draft Model:              {linear:.1f} t/s ({linear/baseline:.2f}Ã—) [+{(linear-baseline)/baseline*100:.1f}%]")
    print(f"3. + Multi-path:               {tree_no_prune:.1f} t/s ({tree_no_prune/baseline:.2f}Ã—) [+{(tree_no_prune-linear)/linear*100:.1f}%]")
    print(f"4. + Adaptive Pruning:         {full:.1f} t/s ({full/baseline:.2f}Ã—) [+{(full-tree_no_prune)/tree_no_prune*100:.1f}%]")
    print("="*80)

if __name__ == "__main__":
    main()
```

**è¿è¡Œ**:
```bash
cd /root/LLM-Efficient-Reasoning
python papers/run_ablation_study.py
```

---

## ğŸ“Š **é¢„æœŸçš„æ¶ˆèå®éªŒç»“æœ**

### **Forward Ablation (é€æ­¥æ·»åŠ )**

| Step | Components | Config | Throughput | Speedup | Contribution |
|------|-----------|--------|-----------|---------|--------------|
| 1 | Baseline | AR only | 127.9 t/s | 1.00Ã— | - |
| 2 | + Draft Model | Linear K=6 | 174.2 t/s | 1.36Ã— | **+36%** (drafting) |
| 3 | + Multi-path | Tree D=7, B=2, t=1.0 | ~160 t/s (é¢„æœŸ) | ~1.25Ã— | **-8%** (no pruning overhead) |
| 4 | + Adaptive Pruning | Tree D=7, B=2, t=0.05 | 196.4 t/s | 1.54Ã— | **+23%** (pruning benefit) |

**å…³é”®å‘ç°**:
1. Draft Model æä¾›æœ€å¤§è´¡çŒ® (+36%)
2. Multi-path åœ¨**æ²¡æœ‰å‰ªææ—¶åè€Œé™ä½æ€§èƒ½**ï¼ˆéªŒè¯å¼€é”€ï¼‰
3. Adaptive Pruning æ˜¯å…³é”®ï¼šä½¿å¤šè·¯å¾„æ¢ç´¢å˜å¾—é«˜æ•ˆ (+23%)

---

### **Backward Ablation (é€æ­¥ç§»é™¤)**

| Step | Removed | Config | Throughput | Speedup | Loss |
|------|---------|--------|-----------|---------|------|
| 1 | None (Full) | Tree D=7, B=2, t=0.05 | 196.4 t/s | 1.54Ã— | - |
| 2 | - Pruning | Tree D=7, B=2, t=1.0 | ~160 t/s | ~1.25Ã— | **-18%** |
| 3 | - Multi-path | Tree D=7, B=1, t=0.05 | ~174 t/s | ~1.36Ã— | **-11%** |
| 4 | - Draft Model | AR only | 127.9 t/s | 1.00Ã— | **-35%** |

**å…³é”®å‘ç°**:
1. ç§»é™¤ä»»ä½•ç»„ä»¶éƒ½ä¼šé™ä½æ€§èƒ½
2. Draft Model æœ€å…³é”® (ç§»é™¤å -35%)
3. Pruning å¯¹æ€§èƒ½å½±å“æ˜¾è‘— (ç§»é™¤å -18%)

---

## ğŸ“ **æ¶ˆèå®éªŒçš„ LaTeX è¡¨æ ¼**

### **æ–¹æ¡ˆ A: Forward Ablation**

```latex
\subsection{Ablation Study}

To isolate the contribution of each algorithmic component, we conduct an ablation study by progressively adding features to the baseline autoregressive decoder. Table~\ref{tab:ablation} summarizes the results. Starting from pure autoregressive generation (127.9 tokens/s), introducing speculative decoding with a draft model (Linear K=6) yields a 36\% improvement (174.2 tokens/s), demonstrating the core benefit of parallel verification. Adding multi-path tree exploration without pruning (D=7, B=2, $\tau$=1.0) initially degrades performance to $\sim$160 tokens/s, as the verification overhead of a large unpruned tree outweighs exploration benefits. Finally, enabling adaptive probability-threshold pruning ($\tau$=0.05) recovers performance and achieves 196.4 tokens/s (1.54$\times$ speedup), demonstrating that selective pruning is essential to balance exploration breadth with verification efficiency.

\begin{table}[t]
\centering
\caption{\textbf{Ablation study: progressive component addition.} Each row adds one algorithmic component to the system. The results demonstrate that while draft-based speculation provides the primary acceleration, adaptive pruning is essential to make multi-path exploration efficient.}
\label{tab:ablation}
\begin{tabular}{llccc}
    \toprule
Step & Components & Configuration & Throughput & Speedup \\
    \midrule
1 & Baseline & AR only & 127.9 & 1.00\(\times\) \\
2 & + Draft model & Linear K=6 & 174.2 & 1.36\(\times\) \\
3 & + Multi-path & Tree D=7, B=2, $\tau$=1.0 & 160.0 & 1.25\(\times\) \\
\textbf{4} & \textbf{+ Adaptive pruning} & \textbf{Tree D=7, B=2, $\tau$=0.05} & \textbf{196.4} & \textbf{1.54\(\times\)} \\
    \bottomrule
  \end{tabular}
\end{table}
```

---

## âœ… **å¦‚æœä½ æƒ³åšçœŸæ­£çš„æ¶ˆèå®éªŒï¼Œéœ€è¦åšä»€ä¹ˆï¼Ÿ**

### **æœ€å°æ­¥éª¤ï¼ˆåªéœ€1ä¸ªå®éªŒï¼‰**:

1. **è·‘ Tree without pruning**:
   ```bash
   python papers/run_single_config.py --depth 7 --branch 2 --threshold 1.0 --tokens 500
   ```
   é¢„è®¡æ—¶é—´: 5 åˆ†é’Ÿ

2. **æ„å»ºæ¶ˆèè¡¨æ ¼**:
   - Baseline: 127.9 t/s (å·²æœ‰)
   - Linear: 174.2 t/s (å·²æœ‰)
   - Tree no-prune: [å®éªŒç»“æœ] t/s
   - Full DynaTree: 196.4 t/s (å·²æœ‰)

3. **å†™å…¥è®ºæ–‡**:
   - æ·»åŠ  Section 4.3 "Ablation Study"
   - ä½¿ç”¨ä¸Šé¢çš„ LaTeX è¡¨æ ¼æ¨¡æ¿
   - è§£é‡Šæ¯ä¸ªç»„ä»¶çš„è´¡çŒ®

---

### **å®Œæ•´ç‰ˆæœ¬ï¼ˆæ¨èï¼Œéœ€è¦2-3ä¸ªå®éªŒï¼‰**:

1. Tree without pruning (t=1.0)
2. Tree single branch (B=1)
3. (å¯é€‰) Tree shallow (D=1)

æ€»æ—¶é—´: 10-15 åˆ†é’Ÿ

---

## ğŸ¯ **å†³ç­–å»ºè®®**

### **å¦‚æœæ—¶é—´ç´§**:
- ä¸åšæ¶ˆèå®éªŒï¼ˆå½“å‰çŠ¶æ€ï¼‰
- å‚æ•°æ•æ„Ÿæ€§åˆ†æå·²ç»å¾ˆå…¨é¢äº†

### **å¦‚æœæƒ³è¦æ›´å®Œæ•´çš„è®ºæ–‡**:
- èŠ± 5 åˆ†é’Ÿè·‘ 1 ä¸ªå®éªŒï¼ˆTree no-pruningï¼‰
- æ·»åŠ ç®€å•çš„æ¶ˆèè¡¨æ ¼
- è¿™ä¼šæ˜¾è‘—æå‡è®ºæ–‡è´¨é‡

### **å¦‚æœè¿½æ±‚å®Œç¾**:
- èŠ± 15 åˆ†é’Ÿè·‘ 3 ä¸ªå®éªŒ
- åšå®Œæ•´çš„ forward + backward ablation
- è¿™æ˜¯é¡¶ä¼šè®ºæ–‡çš„æ ‡å‡†

---

## ğŸ“Œ **æ€»ç»“**

**çœŸæ­£çš„æ¶ˆèå®éªŒéœ€è¦**:
1. âœ… é€æ­¥æ·»åŠ /ç§»é™¤**ç»„ä»¶**ï¼ˆä¸æ˜¯å‚æ•°ï¼‰
2. âœ… è¯æ˜æ¯ä¸ªç»„ä»¶çš„**ç‹¬ç«‹è´¡çŒ®**
3. âœ… æ‰€æœ‰æ•°æ®å¿…é¡»æ˜¯**çœŸå®å®éªŒ**çš„ç»“æœ

**ä½ å½“å‰ç¼ºå°‘çš„**:
- âŒ Tree without pruning (t=1.0) çš„æ•°æ®

**æœ€å°æˆæœ¬æ–¹æ¡ˆ**:
- åªéœ€è·‘ 1 ä¸ªå®éªŒï¼ˆ5åˆ†é’Ÿï¼‰
- å°±å¯ä»¥åšä¸€ä¸ªçœŸæ­£çš„æ¶ˆèå®éªŒ

**å¦‚æœä½ æƒ³åšï¼Œå‘Šè¯‰æˆ‘ï¼Œæˆ‘å¯ä»¥å¸®ä½ ï¼š**
1. åˆ›å»ºå®éªŒè„šæœ¬
2. è¿è¡Œå®éªŒ
3. ç”Ÿæˆè¡¨æ ¼å’Œå›¾è¡¨
4. æ›´æ–°è®ºæ–‡

---

**ç°åœ¨çš„è®ºæ–‡æ²¡æœ‰æ¶ˆèå®éªŒï¼Œä½†æœ‰éå¸¸å…¨é¢çš„å‚æ•°æ•æ„Ÿæ€§åˆ†æï¼Œè¿™ä¹Ÿæ˜¯å¯ä»¥æ¥å—çš„ï¼**

