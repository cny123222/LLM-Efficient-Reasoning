# Benchmark è„šæœ¬æ›´æ–°è¯´æ˜

æœ¬æ–‡æ¡£è¯´æ˜ benchmark.py è„šæœ¬çš„æœ€æ–°æ›´æ–°å†…å®¹ï¼ŒåŒ…æ‹¬ VRAM æµ‹é‡ã€ç»“æœä¿å­˜å’Œå¯è§†åŒ–åŠŸèƒ½ã€‚

---

## ğŸ¯ æ›´æ–°å†…å®¹

### 1. VRAM Usage æµ‹é‡

#### ä¿®æ”¹æ–‡ä»¶ï¼š`kvcompress/benchmark.py`

**æ–°å¢åŠŸèƒ½**ï¼š
- åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­è‡ªåŠ¨æµ‹é‡å³°å€¼æ˜¾å­˜å ç”¨
- æ”¯æŒ CUDA è®¾å¤‡çš„æ˜¾å­˜ç›‘æ§
- è¿”å›ç»“æœä¸­åŒ…å« `peak_vram_gb` å­—æ®µï¼ˆå•ä½ï¼šGBï¼‰

**å®ç°ç»†èŠ‚**ï¼š
```python
# åœ¨ç”Ÿæˆå¼€å§‹å‰é‡ç½®æ˜¾å­˜ç»Ÿè®¡
if device.type == "cuda":
    torch.cuda.reset_peak_memory_stats(device)

# åœ¨ç”Ÿæˆç»“æŸåè·å–å³°å€¼æ˜¾å­˜
peak_memory_bytes = torch.cuda.max_memory_allocated(device)
peak_memory_gb = peak_memory_bytes / (1024 ** 3)
```

**è¿”å›å€¼**ï¼š
- æ–°å¢å­—æ®µï¼š`peak_vram_gb` - å³°å€¼æ˜¾å­˜å ç”¨ï¼ˆGBï¼‰

---

### 2. ç»“æœä¿å­˜åŠŸèƒ½

#### ä¿®æ”¹æ–‡ä»¶ï¼š`scripts/benchmark.py`

**æ–°å¢åŠŸèƒ½**ï¼š
- è‡ªåŠ¨åˆ›å»ºæ—¶é—´æˆ³å‘½åçš„ç»“æœç›®å½•
- ä¿å­˜å®Œæ•´çš„ JSON æ ¼å¼ç»“æœ
- ç›®å½•å‘½åæ ¼å¼ï¼š`{method}_{model}_{timestamp}`

**ç›®å½•ç»“æ„**ï¼š
```
results/
â”œâ”€â”€ streaming_llm_pythia-2.8b_20241230_153045/
â”‚   â”œâ”€â”€ results.json              # å®Œæ•´çš„å®éªŒç»“æœ
â”‚   â””â”€â”€ benchmark_comparison.png  # å¯¹æ¯”å›¾è¡¨
â”œâ”€â”€ fix_size_l2_pythia-2.8b_20241230_160230/
â”‚   â”œâ”€â”€ results.json
â”‚   â””â”€â”€ benchmark_comparison.png
â””â”€â”€ ...
```

**JSON æ ¼å¼**ï¼š
```json
{
  "config": {
    "model_id": "/mnt/disk1/models/pythia-2.8b",
    "method": "streaming_llm",
    "num_samples": 3,
    "max_tokens": 2000,
    "max_new_tokens": 500,
    "skip_layers": [0, 1],
    "timestamp": "20241230_153045"
  },
  "raw_results": [
    {
      "method": "baseline",
      "ttft": 0.0123,
      "tpot": 0.0045,
      "throughput": 156.78,
      "perplexity": 42.35,
      "accuracy": 0.3567,
      "peak_vram_gb": 5.23,
      "final_cache_size": 2000
    },
    ...
  ],
  "aggregated_stats": {
    "baseline": {
      "ttft": 0.0123,
      "tpot": 0.0045,
      "throughput": 156.78,
      "perplexity": 42.35,
      "accuracy": 0.3567,
      "peak_vram_gb": 5.23,
      "cache_size": 2000
    },
    "streaming_512": { ... }
  },
  "baseline_stats": {
    "perplexity": 42.35,
    "accuracy": 0.3567,
    "throughput": 156.78,
    "tpot": 0.0045
  }
}
```

---

### 3. å¯è§†åŒ–å¯¹æ¯”å›¾è¡¨

#### æ–°å¢åŠŸèƒ½ï¼š`plot_benchmark_results()`

**ç”Ÿæˆå›¾è¡¨**ï¼š`benchmark_comparison.png`

**å¸ƒå±€**ï¼š2 è¡Œ Ã— 3 åˆ—ï¼Œå…± 6 ä¸ªå­å›¾

| è¡Œ | åˆ— 1 | åˆ— 2 | åˆ— 3 |
|----|------|------|------|
| ç¬¬ 1 è¡Œ | Throughput<br>(ååé‡) | TPOT<br>(æ¯ token æ—¶é—´) | TTFT<br>(é¦– token æ—¶é—´) |
| ç¬¬ 2 è¡Œ | Perplexity<br>(å›°æƒ‘åº¦) | **VRAM Usage**<br>(æ˜¾å­˜å ç”¨) | Cache Size<br>(ç¼“å­˜å¤§å°) |

**å›¾è¡¨ç‰¹ç‚¹**ï¼š
- é¢œè‰²ç¼–ç ï¼š
  - `baseline`: ç°è‰²
  - `streaming_*`: ç»¿è‰²
  - `recent_only_*`: çº¢è‰²
  - å…¶ä»–æ–¹æ³•ï¼šè“è‰²
- æ¯ä¸ªæŸ±çŠ¶å›¾ä¸Šæ ‡æ³¨å…·ä½“æ•°å€¼
- è‡ªåŠ¨è°ƒæ•´ Y è½´èŒƒå›´ä»¥çªå‡ºå·®å¼‚
- é«˜åˆ†è¾¨ç‡è¾“å‡ºï¼ˆDPI=300ï¼‰

**å‚è€ƒè®¾è®¡**ï¼š
å‚ç…§ `precision/precision_benchmark_2rows.png` çš„æ ·å¼ï¼Œé‡‡ç”¨ 2 è¡Œå¸ƒå±€å±•ç¤º 6 ä¸ªå…³é”®æŒ‡æ ‡ã€‚

---

## ğŸ“Š æ–°å¢æµ‹é‡æŒ‡æ ‡

### VRAM Usage (Peak Memory)

| æŒ‡æ ‡ | è¯´æ˜ | å•ä½ | æµ‹é‡æ–¹å¼ |
|------|------|------|---------|
| **Peak VRAM** | å³°å€¼æ˜¾å­˜å ç”¨ | GB | `torch.cuda.max_memory_allocated()` |

**é‡è¦æ€§**ï¼š
- è¯„ä¼°ä¸åŒå‹ç¼©æ–¹æ³•çš„æ˜¾å­˜èŠ‚çœæ•ˆæœ
- å¯¹æ¯” baseline å’Œå‹ç¼©æ–¹æ³•çš„å†…å­˜å¼€é”€
- æŒ‡å¯¼å®é™…éƒ¨ç½²æ—¶çš„èµ„æºè§„åˆ’

**é¢„æœŸç»“æœ**ï¼š
- Baseline: æœ€é«˜æ˜¾å­˜å ç”¨ï¼ˆKV cache å®Œæ•´ä¿ç•™ï¼‰
- StreamingLLM: æ˜¾å­˜å ç”¨éš cache å¤§å°å›ºå®š
- Fix-Size: æ˜¾å­˜å ç”¨å¯æ§ï¼ˆå›ºå®šå¤§å°ï¼‰

---

## ğŸš€ ä½¿ç”¨æ–¹å¼

### åŸºæœ¬ç”¨æ³•

```bash
# æµ‹è¯• StreamingLLM æ–¹æ³•
python scripts/benchmark.py \
    --method streaming_llm \
    --model_id /mnt/disk1/models/pythia-2.8b \
    --num_samples 3 \
    --max_tokens 2000

# ç»“æœä¼šè‡ªåŠ¨ä¿å­˜åˆ°ï¼š
# results/streaming_llm_pythia-2.8b_YYYYMMDD_HHMMSS/
```

### è¾“å‡ºè¯´æ˜

#### 1. æ§åˆ¶å°è¾“å‡ºï¼ˆå¢å¼ºç‰ˆï¼‰

```
Method                    TTFT(s)    TPOT(s)    Thruput        PPL        Acc   VRAM(GB)    Cache
----------------------------------------------------------------------------------------------------
baseline                   0.0123     0.0045     156.78      42.35     35.67%       5.23     2000
streaming_256              0.0098     0.0052     142.31      45.12     34.89%       3.21      256
streaming_512              0.0105     0.0048     148.56      43.67     35.23%       4.12      512
streaming_1024             0.0115     0.0046     152.34      42.89     35.45%       4.98     1024
====================================================================================================
```

**æ–°å¢åˆ—**ï¼š`VRAM(GB)` - æ˜¾ç¤ºæ¯ä¸ªæ–¹æ³•çš„å³°å€¼æ˜¾å­˜å ç”¨

#### 2. JSON ç»“æœæ–‡ä»¶

ä½ç½®ï¼š`results/{method}_{model}_{timestamp}/results.json`

åŒ…å«ï¼š
- å®Œæ•´é…ç½®ä¿¡æ¯
- æ¯ä¸ªæ ·æœ¬çš„åŸå§‹ç»“æœ
- èšåˆç»Ÿè®¡æ•°æ®
- Baseline å¯¹æ¯”æ•°æ®

#### 3. å¯¹æ¯”å›¾è¡¨

ä½ç½®ï¼š`results/{method}_{model}_{timestamp}/benchmark_comparison.png`

åŒ…å«ï¼š
- 6 ä¸ªå…³é”®æŒ‡æ ‡çš„æŸ±çŠ¶å›¾å¯¹æ¯”
- é¢œè‰²ç¼–ç åŒºåˆ†ä¸åŒæ–¹æ³•ç±»å‹
- æ•°å€¼æ ‡æ³¨ä¾¿äºè¯»å–

---

## ğŸ“ˆ ç¤ºä¾‹è¾“å‡º

### å®éªŒåœºæ™¯

```bash
python scripts/benchmark.py \
    --method streaming_llm \
    --start_size 4 \
    --recent_sizes 252,508,1020 \
    --model_id /mnt/disk1/models/pythia-2.8b \
    --num_samples 3
```

### ç”Ÿæˆçš„æ–‡ä»¶

```
results/streaming_llm_pythia-2.8b_20241230_153045/
â”œâ”€â”€ results.json              # å®Œæ•´ç»“æœ JSON
â””â”€â”€ benchmark_comparison.png  # å¯è§†åŒ–å¯¹æ¯”å›¾
```

### å¯¹æ¯”å›¾ç¤ºä¾‹

å›¾è¡¨å±•ç¤º 7 ä¸ªå®éªŒç»„çš„å¯¹æ¯”ï¼š
1. **baseline** (ç°è‰²) - æ— å‹ç¼©
2. **recent_only_256** (çº¢è‰²) - æ»‘åŠ¨çª—å£ 256
3. **streaming_256** (ç»¿è‰²) - StreamingLLM 256
4. **recent_only_512** (çº¢è‰²) - æ»‘åŠ¨çª—å£ 512
5. **streaming_512** (ç»¿è‰²) - StreamingLLM 512
6. **recent_only_1024** (çº¢è‰²) - æ»‘åŠ¨çª—å£ 1024
7. **streaming_1024** (ç»¿è‰²) - StreamingLLM 1024

---

## ğŸ” VRAM æµ‹é‡è¯¦è§£

### æµ‹é‡æ—¶æœº

```python
# 1. é‡ç½®ç»Ÿè®¡ï¼ˆç”Ÿæˆå¼€å§‹å‰ï¼‰
torch.cuda.reset_peak_memory_stats(device)

# 2. æ‰§è¡Œç”Ÿæˆè¿‡ç¨‹
# - Prefill é˜¶æ®µ
# - é€ token ç”Ÿæˆ
# - KV cache å‹ç¼©ï¼ˆå¦‚æœå¯ç”¨ï¼‰

# 3. è·å–å³°å€¼ï¼ˆç”Ÿæˆç»“æŸåï¼‰
peak_memory = torch.cuda.max_memory_allocated(device)
```

### æµ‹é‡èŒƒå›´

**åŒ…å«**ï¼š
- æ¨¡å‹å‚æ•°å ç”¨
- è¾“å…¥æ•°æ®å ç”¨
- KV cache å ç”¨ï¼ˆå‹ç¼©å‰åï¼‰
- ä¸­é—´è®¡ç®—çš„ä¸´æ—¶å†…å­˜
- æ¢¯åº¦å†…å­˜ï¼ˆæ¨ç†æ—¶ä¸º 0ï¼‰

**ä¸åŒ…å«**ï¼š
- æ¨¡å‹åŠ è½½å‰çš„å…¶ä»–æ˜¾å­˜å ç”¨
- å…¶ä»–è¿›ç¨‹çš„æ˜¾å­˜å ç”¨

### é¢„æœŸå·®å¼‚

| æ–¹æ³• | é¢„æœŸ VRAM | ç›¸æ¯” Baseline |
|------|-----------|--------------|
| Baseline | æœ€é«˜ | åŸºå‡† (100%) |
| StreamingLLM 256 | è¾ƒä½ | çº¦ 60-70% |
| StreamingLLM 512 | ä¸­ç­‰ | çº¦ 75-85% |
| StreamingLLM 1024 | è¾ƒé«˜ | çº¦ 90-95% |

**å…¬å¼ä¼°ç®—**ï¼š
```
VRAM â‰ˆ æ¨¡å‹å¤§å° + KV cache å¤§å° + ä¸´æ—¶è®¡ç®—å†…å­˜

KV cache å¤§å° = (batch Ã— layers Ã— heads Ã— seq_len Ã— head_dim Ã— 2) Ã— 2 bytes
                â†‘batch=1  â†‘key+value                           â†‘FP16
```

---

## ğŸ¨ å›¾è¡¨æ ·å¼å‚è€ƒ

å‚è€ƒ `precision/precision_benchmark_2rows.png` çš„è®¾è®¡ï¼š
- 2 è¡Œ 3 åˆ—å¸ƒå±€
- æ¸…æ™°çš„æ ‡é¢˜å’Œåæ ‡è½´æ ‡ç­¾
- æŸ±çŠ¶å›¾ä¸Šæ–¹æ ‡æ³¨æ•°å€¼
- é¢œè‰²åŒºåˆ†ä¸åŒæ–¹æ³•ç±»å‹
- ç½‘æ ¼çº¿è¾…åŠ©è¯»æ•°
- é«˜åˆ†è¾¨ç‡è¾“å‡º

---

## ğŸ“ æ³¨æ„äº‹é¡¹

### 1. VRAM æµ‹é‡ç²¾åº¦

- åªåœ¨ CUDA è®¾å¤‡ä¸Šå‡†ç¡®
- MPS å’Œ CPU è¿”å› 0.0
- åŒ…å«æ‰€æœ‰ PyTorch ç®¡ç†çš„æ˜¾å­˜

### 2. ç»“æœç›®å½•ç®¡ç†

- æ¯æ¬¡è¿è¡Œåˆ›å»ºæ–°ç›®å½•
- ç›®å½•ååŒ…å«æ—¶é—´æˆ³ï¼Œé¿å…è¦†ç›–
- å»ºè®®å®šæœŸæ¸…ç†æ—§ç»“æœ

### 3. å›¾è¡¨ç”Ÿæˆ

- ä½¿ç”¨éäº¤äº’å¼åç«¯ï¼ˆ`Agg`ï¼‰
- é€‚åˆæœåŠ¡å™¨ç¯å¢ƒè¿è¡Œ
- è‡ªåŠ¨ä¿å­˜ä¸ºé«˜åˆ†è¾¨ç‡ PNG

### 4. æ€§èƒ½å¼€é”€

- VRAM æµ‹é‡å¼€é”€æå°ï¼ˆ< 1%ï¼‰
- JSON ä¿å­˜å’Œç»˜å›¾åœ¨å®éªŒç»“æŸåè¿›è¡Œ
- ä¸å½±å“å®é™…æµ‹é‡ç»“æœ

---

## ğŸ”§ ä»£ç ä¿®æ”¹ä½ç½®

### 1. `kvcompress/benchmark.py`

**ä¿®æ”¹å‡½æ•°**ï¼š`measure_generation_metrics()`

**ä¿®æ”¹å†…å®¹**ï¼š
- Line ~75: æ·»åŠ  `torch.cuda.reset_peak_memory_stats()`
- Line ~135: æ·»åŠ  VRAM æµ‹é‡é€»è¾‘
- Line ~145: è¿”å›å€¼å¢åŠ  `peak_vram_gb` å­—æ®µ

### 2. `scripts/benchmark.py`

**æ–°å¢å¯¼å…¥**ï¼š
```python
import json
from datetime import datetime
import matplotlib.pyplot as plt
```

**æ–°å¢å‡½æ•°**ï¼š
- `save_results_to_json()` - ä¿å­˜ JSON ç»“æœ
- `plot_benchmark_results()` - ç”Ÿæˆå¯¹æ¯”å›¾è¡¨

**ä¿®æ”¹å†…å®¹**ï¼š
- Line ~480: åˆ›å»ºç»“æœç›®å½•
- Line ~550: æ‰“å°è¾“å‡ºå¢åŠ  VRAM åˆ—
- Line ~590: ä¿å­˜ JSON å’Œç”Ÿæˆå›¾è¡¨

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [STREAMINGLLM_BENCHMARK_CONFIG.md](./STREAMINGLLM_BENCHMARK_CONFIG.md) - StreamingLLM å®éªŒé…ç½®è¯´æ˜
- [æ¨¡å—åŠŸèƒ½è¯´æ˜.md](../æ¨¡å—åŠŸèƒ½è¯´æ˜.md) - precision å’Œ spec_decode æ¨¡å—è¯´æ˜

---

*æ–‡æ¡£ç”Ÿæˆæ—¶é—´: 2024-12-30*
*æ›´æ–°ç‰ˆæœ¬: v1.1*

