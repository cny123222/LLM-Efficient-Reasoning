#!/usr/bin/env python3
"""
ä¸‹è½½ AWQ é‡åŒ–ç‰ˆæœ¬çš„ Pythia-2.8B æ¨¡å‹

ä»é­”å¡”ç¤¾åŒº (ModelScope) ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°ã€‚

Usage:
    python download_pythia_awq.py

æ³¨æ„:
    - éœ€è¦å®‰è£… modelscope: pip install modelscope
    - æ¨¡å‹å¤§å°çº¦ 1.5GB (AWQ INT4 é‡åŒ–)
    - ä¸‹è½½è·¯å¾„: /mnt/disk1/models/pythia-2.8b-awq
"""

import os
import sys

# ä¸‹è½½é…ç½®
MODEL_SAVE_PATH = "/mnt/disk1/models/pythia-2.8b-awq"

# å°è¯•å¤šä¸ªå¯èƒ½çš„æ¨¡å‹æº
# æ³¨æ„: TheBloke çš„æ¨¡å‹ä¸»è¦åœ¨ HuggingFaceï¼Œé­”å¡”ç¤¾åŒºå¯èƒ½æ²¡æœ‰ç›´æ¥é•œåƒ
# å¦‚æœé­”å¡”æ²¡æœ‰ï¼Œå¯ä»¥ä½¿ç”¨ HuggingFace é•œåƒæˆ–ç›´æ¥ä¸‹è½½

def download_from_modelscope():
    """ä»é­”å¡”ç¤¾åŒºä¸‹è½½"""
    try:
        from modelscope import snapshot_download
        
        print("=" * 60)
        print("ä»é­”å¡”ç¤¾åŒºä¸‹è½½ AWQ é‡åŒ–æ¨¡å‹")
        print("=" * 60)
        
        # é­”å¡”ç¤¾åŒºå¯èƒ½çš„æ¨¡å‹åç§°
        # æ³¨æ„: éœ€è¦å…ˆåœ¨ https://modelscope.cn ä¸Šæœç´¢ç¡®è®¤æ¨¡å‹æ˜¯å¦å­˜åœ¨
        possible_models = [
            "TheBloke/pythia-2.8B-AWQ",           # åŸå§‹åç§°
            "Pythia/pythia-2.8b-awq",             # å¯èƒ½çš„å˜ä½“
            "quantization/pythia-2.8b-awq",       # å¯èƒ½çš„åˆ†ç±»
        ]
        
        print(f"\nç›®æ ‡ä¿å­˜è·¯å¾„: {MODEL_SAVE_PATH}")
        print("\nå°è¯•ä»é­”å¡”ç¤¾åŒºä¸‹è½½...")
        print("æ³¨æ„: å¦‚æœæ¨¡å‹åœ¨é­”å¡”ç¤¾åŒºä¸å­˜åœ¨ï¼Œå°†è‡ªåŠ¨å°è¯• HuggingFace é•œåƒ\n")
        
        for model_id in possible_models:
            try:
                print(f"å°è¯•ä¸‹è½½: {model_id}")
                model_dir = snapshot_download(
                    model_id,
                    cache_dir=os.path.dirname(MODEL_SAVE_PATH),
                    local_dir=MODEL_SAVE_PATH,
                )
                print(f"\nâœ… ä¸‹è½½æˆåŠŸ!")
                print(f"æ¨¡å‹è·¯å¾„: {model_dir}")
                return True
            except Exception as e:
                print(f"  âŒ å¤±è´¥: {e}")
                continue
        
        return False
        
    except ImportError:
        print("âŒ modelscope æœªå®‰è£…")
        print("è¯·è¿è¡Œ: pip install modelscope")
        return False


def download_from_huggingface():
    """ä» HuggingFace (ä½¿ç”¨é•œåƒ) ä¸‹è½½"""
    try:
        # è®¾ç½® HuggingFace é•œåƒ
        os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
        
        from huggingface_hub import snapshot_download
        
        print("\n" + "=" * 60)
        print("ä» HuggingFace é•œåƒä¸‹è½½ AWQ é‡åŒ–æ¨¡å‹")
        print("=" * 60)
        
        model_id = "TheBloke/pythia-2.8b-AWQ"
        
        print(f"\næ¨¡å‹: {model_id}")
        print(f"ç›®æ ‡è·¯å¾„: {MODEL_SAVE_PATH}")
        print(f"ä½¿ç”¨é•œåƒ: https://hf-mirror.com")
        print("\nå¼€å§‹ä¸‹è½½...\n")
        
        model_dir = snapshot_download(
            repo_id=model_id,
            local_dir=MODEL_SAVE_PATH,
            local_dir_use_symlinks=False,
            resume_download=True,
        )
        
        print(f"\nâœ… ä¸‹è½½æˆåŠŸ!")
        print(f"æ¨¡å‹è·¯å¾„: {model_dir}")
        return True
        
    except ImportError:
        print("âŒ huggingface_hub æœªå®‰è£…")
        print("è¯·è¿è¡Œ: pip install huggingface_hub")
        return False
    except Exception as e:
        print(f"âŒ HuggingFace ä¸‹è½½å¤±è´¥: {e}")
        return False


def download_from_huggingface_direct():
    """ç›´æ¥ä» HuggingFace ä¸‹è½½ (ä¸ä½¿ç”¨é•œåƒ)"""
    try:
        # æ¸…é™¤é•œåƒè®¾ç½®
        if "HF_ENDPOINT" in os.environ:
            del os.environ["HF_ENDPOINT"]
        
        from huggingface_hub import snapshot_download
        
        print("\n" + "=" * 60)
        print("ç›´æ¥ä» HuggingFace ä¸‹è½½ (éœ€è¦ç½‘ç»œç•…é€š)")
        print("=" * 60)
        
        model_id = "TheBloke/pythia-2.8b-AWQ"
        
        print(f"\næ¨¡å‹: {model_id}")
        print(f"ç›®æ ‡è·¯å¾„: {MODEL_SAVE_PATH}")
        print("\nå¼€å§‹ä¸‹è½½...\n")
        
        model_dir = snapshot_download(
            repo_id=model_id,
            local_dir=MODEL_SAVE_PATH,
            local_dir_use_symlinks=False,
            resume_download=True,
        )
        
        print(f"\nâœ… ä¸‹è½½æˆåŠŸ!")
        print(f"æ¨¡å‹è·¯å¾„: {model_dir}")
        return True
        
    except Exception as e:
        print(f"âŒ ç›´æ¥ä¸‹è½½å¤±è´¥: {e}")
        return False


def verify_model():
    """éªŒè¯ä¸‹è½½çš„æ¨¡å‹"""
    print("\n" + "=" * 60)
    print("éªŒè¯æ¨¡å‹æ–‡ä»¶")
    print("=" * 60)
    
    if not os.path.exists(MODEL_SAVE_PATH):
        print(f"âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {MODEL_SAVE_PATH}")
        return False
    
    # æ£€æŸ¥å…³é”®æ–‡ä»¶
    required_files = ["config.json"]
    awq_files = ["model.safetensors", "pytorch_model.bin", "quant_config.json"]
    
    files = os.listdir(MODEL_SAVE_PATH)
    print(f"\næ¨¡å‹æ–‡ä»¶åˆ—è¡¨:")
    for f in sorted(files):
        size = os.path.getsize(os.path.join(MODEL_SAVE_PATH, f))
        size_str = f"{size / 1024 / 1024:.1f} MB" if size > 1024 * 1024 else f"{size / 1024:.1f} KB"
        print(f"  - {f} ({size_str})")
    
    # æ£€æŸ¥å¿…éœ€æ–‡ä»¶
    missing = [f for f in required_files if f not in files]
    if missing:
        print(f"\nâš ï¸  ç¼ºå°‘æ–‡ä»¶: {missing}")
    
    # æ£€æŸ¥ AWQ æ–‡ä»¶
    has_awq = any(f in files for f in awq_files)
    if has_awq:
        print("\nâœ… AWQ æ¨¡å‹æ–‡ä»¶éªŒè¯é€šè¿‡")
    else:
        print("\nâš ï¸  æœªæ‰¾åˆ° AWQ æƒé‡æ–‡ä»¶ï¼Œå¯èƒ½ä¸‹è½½ä¸å®Œæ•´")
    
    return has_awq


def main():
    print("\n" + "=" * 60)
    print("   Pythia-2.8B AWQ é‡åŒ–æ¨¡å‹ä¸‹è½½è„šæœ¬")
    print("=" * 60)
    print(f"\nç›®æ ‡è·¯å¾„: {MODEL_SAVE_PATH}")
    
    # æ£€æŸ¥ç›®å½•æ˜¯å¦å·²å­˜åœ¨
    if os.path.exists(MODEL_SAVE_PATH):
        files = os.listdir(MODEL_SAVE_PATH)
        if files:
            print(f"\nâš ï¸  ç›®å½•å·²å­˜åœ¨ä¸”ä¸ä¸ºç©ºï¼ŒåŒ…å« {len(files)} ä¸ªæ–‡ä»¶")
            response = input("æ˜¯å¦ç»§ç»­ä¸‹è½½ (ä¼šè¦†ç›–)? [y/N]: ").strip().lower()
            if response != 'y':
                print("å–æ¶ˆä¸‹è½½")
                return
    
    # åˆ›å»ºçˆ¶ç›®å½•
    os.makedirs(os.path.dirname(MODEL_SAVE_PATH), exist_ok=True)
    
    # ä¾æ¬¡å°è¯•ä¸åŒçš„ä¸‹è½½æº
    success = False
    
    # 1. å°è¯•é­”å¡”ç¤¾åŒº
    print("\n[1/3] å°è¯•ä»é­”å¡”ç¤¾åŒºä¸‹è½½...")
    success = download_from_modelscope()
    
    # 2. å°è¯• HuggingFace é•œåƒ
    if not success:
        print("\n[2/3] å°è¯•ä» HuggingFace é•œåƒä¸‹è½½...")
        success = download_from_huggingface()
    
    # 3. å°è¯•ç›´æ¥ä» HuggingFace ä¸‹è½½
    if not success:
        print("\n[3/3] å°è¯•ç›´æ¥ä» HuggingFace ä¸‹è½½...")
        success = download_from_huggingface_direct()
    
    # éªŒè¯ä¸‹è½½
    if success:
        verify_model()
        
        print("\n" + "=" * 60)
        print("ğŸ“ ä½¿ç”¨æ–¹æ³•")
        print("=" * 60)
        print(f"""
# å®‰è£… autoawq
pip install autoawq

# åŠ è½½ AWQ æ¨¡å‹
from awq import AutoAWQForCausalLM
from transformers import AutoTokenizer

model = AutoAWQForCausalLM.from_quantized(
    "{MODEL_SAVE_PATH}",
    fuse_layers=True,
    device_map="auto"
)
tokenizer = AutoTokenizer.from_pretrained("{MODEL_SAVE_PATH}")

# ç”Ÿæˆ
inputs = tokenizer("Hello, world!", return_tensors="pt").to("cuda")
outputs = model.generate(**inputs, max_new_tokens=50)
print(tokenizer.decode(outputs[0]))
""")
    else:
        print("\n" + "=" * 60)
        print("âŒ æ‰€æœ‰ä¸‹è½½æ–¹å¼éƒ½å¤±è´¥äº†")
        print("=" * 60)
        print("""
å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:

1. æ‰‹åŠ¨ä» HuggingFace ä¸‹è½½:
   https://huggingface.co/TheBloke/pythia-2.8b-AWQ

2. ä½¿ç”¨ git lfs:
   git lfs install
   git clone https://huggingface.co/TheBloke/pythia-2.8b-AWQ /mnt/disk1/models/pythia-2.8b-awq

3. ä½¿ç”¨ huggingface-cli:
   pip install huggingface_hub
   huggingface-cli download TheBloke/pythia-2.8b-AWQ --local-dir /mnt/disk1/models/pythia-2.8b-awq

4. æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ä½¿ç”¨ä»£ç†
""")


if __name__ == "__main__":
    main()






