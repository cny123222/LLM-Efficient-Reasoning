# Benchmark è„šæœ¬ä½¿ç”¨ç¤ºä¾‹

å¿«é€Ÿå¼€å§‹ä½¿ç”¨æ›´æ–°åçš„ benchmark.py è„šæœ¬ï¼ŒåŒ…å« VRAM æµ‹é‡ã€ç»“æœä¿å­˜å’Œå¯è§†åŒ–åŠŸèƒ½ã€‚

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ

```bash
cd /mnt/disk1/ljm/LLM-Efficient-Reasoning
source ../llm-inference/bin/activate
```

### 2. è¿è¡Œ Benchmark

```bash
# æµ‹è¯• StreamingLLM æ–¹æ³•
python scripts/benchmark.py \
    --method streaming_llm \
    --model_id /mnt/disk1/models/pythia-2.8b \
    --num_samples 3 \
    --max_tokens 2000
```

### 3. æŸ¥çœ‹ç»“æœ

ç»“æœä¼šè‡ªåŠ¨ä¿å­˜åˆ°æ—¶é—´æˆ³å‘½åçš„ç›®å½•ï¼š

```bash
# ç»“æœç›®å½•ç¤ºä¾‹
results/streaming_llm_pythia-2.8b_20241230_153045/
â”œâ”€â”€ results.json              # å®Œæ•´çš„å®éªŒæ•°æ®
â””â”€â”€ benchmark_comparison.png  # å¯¹æ¯”å›¾è¡¨ï¼ˆåŒ…å« VRAMï¼‰
```

---

## ğŸ“Š æ–°å¢åŠŸèƒ½

### 1. VRAM Usage æµ‹é‡

**è‡ªåŠ¨æµ‹é‡å³°å€¼æ˜¾å­˜å ç”¨**ï¼Œæ— éœ€é¢å¤–é…ç½®ï¼š

```bash
# æ§åˆ¶å°è¾“å‡ºç¤ºä¾‹ï¼ˆæ–°å¢ VRAM åˆ—ï¼‰
Method                    TTFT(s)    TPOT(s)    Thruput        PPL        Acc   VRAM(GB)    Cache
----------------------------------------------------------------------------------------------------
baseline                   0.0123     0.0045     156.78      42.35     35.67%       5.23     2000
streaming_256              0.0098     0.0052     142.31      45.12     34.89%       3.21      256
streaming_512              0.0105     0.0048     148.56      43.67     35.23%       4.12      512
streaming_1024             0.0115     0.0046     152.34      42.89     35.45%       4.98     1024
```

### 2. è‡ªåŠ¨ä¿å­˜ç»“æœ

**æ¯æ¬¡è¿è¡Œéƒ½ä¼šåˆ›å»ºç‹¬ç«‹çš„ç»“æœç›®å½•**ï¼ŒåŒ…å«ï¼š

#### results.json
å®Œæ•´çš„å®éªŒæ•°æ®ï¼ŒåŒ…æ‹¬ï¼š
- é…ç½®ä¿¡æ¯ï¼ˆæ¨¡å‹ã€å‚æ•°ç­‰ï¼‰
- æ¯ä¸ªæ ·æœ¬çš„åŸå§‹ç»“æœ
- èšåˆç»Ÿè®¡æ•°æ®
- Baseline å¯¹æ¯”æ•°æ®

#### benchmark_comparison.png
6 ä¸ªå…³é”®æŒ‡æ ‡çš„å¯¹æ¯”å›¾ï¼š

| æŒ‡æ ‡ 1 | æŒ‡æ ‡ 2 | æŒ‡æ ‡ 3 |
|--------|--------|--------|
| Throughput | TPOT | TTFT |
| Perplexity | **VRAM Usage** â­ | Cache Size |

---

## ğŸ¯ å¸¸ç”¨å‘½ä»¤

### æŒ‡å®š GPU è¿è¡Œ

ä½¿ç”¨ `CUDA_VISIBLE_DEVICES` ç¯å¢ƒå˜é‡æŒ‡å®š GPUï¼š

```bash
# åœ¨ GPU 0 ä¸Šè¿è¡Œï¼ˆé»˜è®¤ï¼‰
CUDA_VISIBLE_DEVICES=0 python scripts/benchmark.py --method streaming_llm ...

# åœ¨ GPU 7 ä¸Šè¿è¡Œ
CUDA_VISIBLE_DEVICES=7 python scripts/benchmark.py --method streaming_llm ...

# ä½¿ç”¨å¤šä¸ª GPUï¼ˆä¾‹å¦‚ GPU 6 å’Œ 7ï¼‰
CUDA_VISIBLE_DEVICES=6,7 python scripts/benchmark.py --method streaming_llm ...
```

### æµ‹è¯• StreamingLLM

```bash
# åŸºæœ¬ç”¨æ³•
python scripts/benchmark.py \
    --method streaming_llm \
    --start_size 4 \
    --recent_sizes 252,508,1020 \
    --model_id /mnt/disk1/models/pythia-2.8b \
    --num_samples 3

# åœ¨æŒ‡å®š GPU (GPU 7) ä¸Šè¿è¡Œ
CUDA_VISIBLE_DEVICES=7 python scripts/benchmark.py \
    --method streaming_llm \
    --start_size 4 \
    --recent_sizes 252,508,1020 \
    --model_id /mnt/disk1/models/pythia-2.8b \
    --num_samples 3
```

### æµ‹è¯• Fix-Size L2

```bash
# åŸºæœ¬ç”¨æ³•
python scripts/benchmark.py \
    --method fix_size_l2 \
    --fix_kv_sizes 256,512 \
    --strategies keep_low \
    --keep_ratios 0.5,0.7 \
    --model_id /mnt/disk1/models/pythia-2.8b \
    --num_samples 3

# åœ¨ GPU 7 ä¸Šè¿è¡Œ
CUDA_VISIBLE_DEVICES=7 python scripts/benchmark.py \
    --method fix_size_l2 \
    --fix_kv_sizes 256,512 \
    --strategies keep_low \
    --keep_ratios 0.5,0.7 \
    --model_id /mnt/disk1/models/pythia-2.8b \
    --num_samples 3
```

### å¯¹æ¯”æ‰€æœ‰æ–¹æ³•

```bash
# åŸºæœ¬ç”¨æ³•
python scripts/benchmark.py \
    --compare_all \
    --model_id /mnt/disk1/models/pythia-2.8b \
    --num_samples 3

# åœ¨ GPU 7 ä¸Šè¿è¡Œ
CUDA_VISIBLE_DEVICES=7 python scripts/benchmark.py \
    --compare_all \
    --model_id /mnt/disk1/models/pythia-2.8b \
    --num_samples 3
```

### ä¸åŒ…å«æ§åˆ¶ç»„ï¼ˆåŠ é€Ÿæµ‹è¯•ï¼‰

```bash
python scripts/benchmark.py \
    --method streaming_llm \
    --no_recent_only \
    --model_id /mnt/disk1/models/pythia-2.8b \
    --num_samples 2
```

---

## ğŸ“ˆ ç»“æœåˆ†æ

### æŸ¥çœ‹ JSON ç»“æœ

```bash
# ä½¿ç”¨ jq ç¾åŒ–è¾“å‡º
cat results/streaming_llm_pythia-2.8b_*/results.json | jq '.aggregated_stats'

# æå–ç‰¹å®šæ–¹æ³•çš„ VRAM æ•°æ®
cat results/streaming_llm_pythia-2.8b_*/results.json | jq '.aggregated_stats.streaming_512.peak_vram_gb'
```

### æŸ¥çœ‹å¯¹æ¯”å›¾

```bash
# ä½¿ç”¨å›¾ç‰‡æŸ¥çœ‹å™¨
eog results/streaming_llm_pythia-2.8b_*/benchmark_comparison.png

# æˆ–è€…å¤åˆ¶åˆ°æœ¬åœ°æŸ¥çœ‹
scp user@server:/path/to/results/*/benchmark_comparison.png ./
```

---

## ğŸ” VRAM åˆ†æ

### é¢„æœŸ VRAM å ç”¨

| æ–¹æ³• | Cache å¤§å° | é¢„æœŸ VRAM | ç›¸æ¯” Baseline |
|------|-----------|-----------|--------------|
| Baseline | æ— é™åˆ¶ | æœ€é«˜ | 100% (åŸºå‡†) |
| streaming_256 | 256 | è¾ƒä½ | çº¦ 60-70% |
| streaming_512 | 512 | ä¸­ç­‰ | çº¦ 75-85% |
| streaming_1024 | 1024 | è¾ƒé«˜ | çº¦ 90-95% |

### VRAM èŠ‚çœæ•ˆæœ

```python
# è®¡ç®— VRAM èŠ‚çœç™¾åˆ†æ¯”
vram_saving = (baseline_vram - method_vram) / baseline_vram * 100

# ç¤ºä¾‹ï¼š
# baseline_vram = 5.23 GB
# streaming_512_vram = 4.12 GB
# èŠ‚çœ = (5.23 - 4.12) / 5.23 * 100 = 21.2%
```

---

## ğŸ¨ å›¾è¡¨è¯´æ˜

### benchmark_comparison.png

**å¸ƒå±€**ï¼š2 è¡Œ Ã— 3 åˆ—

**æŒ‡æ ‡è¯´æ˜**ï¼š

1. **Throughput** (å·¦ä¸Š) - ååé‡ï¼Œè¶Šé«˜è¶Šå¥½
   - å•ä½ï¼štokens/second
   - åæ˜ ç”Ÿæˆé€Ÿåº¦

2. **TPOT** (ä¸­ä¸Š) - æ¯ä¸ªè¾“å‡º token çš„æ—¶é—´ï¼Œè¶Šä½è¶Šå¥½
   - å•ä½ï¼šmilliseconds
   - åæ˜ è§£ç æ•ˆç‡

3. **TTFT** (å³ä¸Š) - é¦–ä¸ª token æ—¶é—´ï¼Œè¶Šä½è¶Šå¥½
   - å•ä½ï¼šmilliseconds
   - åæ˜  prefill é€Ÿåº¦

4. **Perplexity** (å·¦ä¸‹) - å›°æƒ‘åº¦ï¼Œè¶Šä½è¶Šå¥½
   - åæ˜ ç”Ÿæˆè´¨é‡
   - ä¸ baseline è¶Šæ¥è¿‘è¶Šå¥½

5. **VRAM Usage** (ä¸­ä¸‹) â­ - å³°å€¼æ˜¾å­˜å ç”¨ï¼Œè¶Šä½è¶Šå¥½
   - å•ä½ï¼šGB
   - åæ˜ å†…å­˜æ•ˆç‡

6. **Cache Size** (å³ä¸‹) - KV cache å¤§å°
   - å•ä½ï¼štokens
   - åæ˜ å†…å­˜å ç”¨

**é¢œè‰²ç¼–ç **ï¼š
- ğŸŸ¦ ç°è‰²ï¼šbaselineï¼ˆæ— å‹ç¼©ï¼‰
- ğŸŸ© ç»¿è‰²ï¼šstreaming_* æ–¹æ³•
- ğŸŸ¥ çº¢è‰²ï¼šrecent_only_* æ§åˆ¶ç»„
- ğŸŸ¦ è“è‰²ï¼šå…¶ä»–å‹ç¼©æ–¹æ³•

---

## ğŸ“ ç»“æœç›®å½•ç»“æ„

```
results/
â”œâ”€â”€ streaming_llm_pythia-2.8b_20241230_153045/
â”‚   â”œâ”€â”€ results.json
â”‚   â””â”€â”€ benchmark_comparison.png
â”œâ”€â”€ fix_size_l2_pythia-2.8b_20241230_160230/
â”‚   â”œâ”€â”€ results.json
â”‚   â””â”€â”€ benchmark_comparison.png
â””â”€â”€ compare_all_pythia-2.8b_20241230_170530/
    â”œâ”€â”€ results.json
    â””â”€â”€ benchmark_comparison.png
```

**å‘½åè§„åˆ™**ï¼š`{method}_{model_name}_{timestamp}`

---

## ğŸ–¥ï¸ GPU é€‰æ‹©è¯´æ˜

### CUDA_VISIBLE_DEVICES ç¯å¢ƒå˜é‡

æ§åˆ¶è„šæœ¬ä½¿ç”¨å“ªä¸ª GPUï¼š

```bash
# æŸ¥çœ‹å¯ç”¨çš„ GPU
nvidia-smi

# ä½¿ç”¨å•ä¸ª GPU
CUDA_VISIBLE_DEVICES=0  # ä½¿ç”¨ GPU 0
CUDA_VISIBLE_DEVICES=7  # ä½¿ç”¨ GPU 7

# ä½¿ç”¨å¤šä¸ª GPUï¼ˆè„šæœ¬ä¼šä½¿ç”¨ç¬¬ä¸€ä¸ªï¼‰
CUDA_VISIBLE_DEVICES=6,7  # å¯è§ GPU 6 å’Œ 7ï¼Œè„šæœ¬ä½¿ç”¨ GPU 6

# ä¸ä½¿ç”¨ GPUï¼ˆä»… CPUï¼‰
CUDA_VISIBLE_DEVICES=""
```

### å¸¸è§åœºæ™¯

```bash
# åœºæ™¯ 1: æœåŠ¡å™¨æœ‰å¤šä¸ª GPUï¼Œæƒ³ä½¿ç”¨ç©ºé—²çš„ GPU 7
CUDA_VISIBLE_DEVICES=7 python scripts/benchmark.py --method streaming_llm ...

# åœºæ™¯ 2: ç¡®ä¿ä½¿ç”¨ç‰¹å®š GPU å¹¶åå°è¿è¡Œ
nohup env CUDA_VISIBLE_DEVICES=7 python scripts/benchmark.py \
    --method streaming_llm \
    --model_id /mnt/disk1/models/pythia-2.8b \
    --num_samples 5 > benchmark.log 2>&1 &

# åœºæ™¯ 3: éªŒè¯ä½¿ç”¨çš„ GPU
CUDA_VISIBLE_DEVICES=7 python -c "import torch; print(f'Using GPU: {torch.cuda.current_device()}')"
```

### æ³¨æ„äº‹é¡¹

1. **GPU ç¼–å·ä» 0 å¼€å§‹**ï¼šGPU 7 æ˜¯ç¬¬ 8 å— GPU
2. **æ£€æŸ¥ GPU å¯ç”¨æ€§**ï¼šè¿è¡Œå‰å…ˆç”¨ `nvidia-smi` æŸ¥çœ‹ GPU çŠ¶æ€
3. **æ˜¾å­˜å ç”¨**ï¼šç¡®ä¿ç›®æ ‡ GPU æœ‰è¶³å¤Ÿçš„æ˜¾å­˜ï¼ˆpythia-2.8b çº¦éœ€ 6-8 GBï¼‰
4. **å¤š GPU åœºæ™¯**ï¼šè„šæœ¬é»˜è®¤åªä½¿ç”¨å• GPUï¼Œè®¾ç½®å¤šä¸ª GPU æ—¶åªä¼šç”¨ç¬¬ä¸€ä¸ª

---

## ğŸ’¡ æç¤º

### 1. å¿«é€Ÿæµ‹è¯•

```bash
# ä½¿ç”¨è¾ƒå°‘æ ·æœ¬å¿«é€Ÿæµ‹è¯•
python scripts/benchmark.py \
    --method streaming_llm \
    --num_samples 1 \
    --max_tokens 1000 \
    --model_id /mnt/disk1/models/pythia-2.8b

# åœ¨ GPU 7 ä¸Šå¿«é€Ÿæµ‹è¯•
CUDA_VISIBLE_DEVICES=7 python scripts/benchmark.py \
    --method streaming_llm \
    --num_samples 1 \
    --max_tokens 1000 \
    --model_id /mnt/disk1/models/pythia-2.8b
```

### 2. å®Œæ•´å®éªŒ

```bash
# ä½¿ç”¨æ›´å¤šæ ·æœ¬è·å¾—ç¨³å®šç»“æœ
python scripts/benchmark.py \
    --method streaming_llm \
    --num_samples 5 \
    --max_tokens 3000 \
    --model_id /mnt/disk1/models/pythia-2.8b

# åœ¨ GPU 7 ä¸Šè¿è¡Œå®Œæ•´å®éªŒ
CUDA_VISIBLE_DEVICES=7 python scripts/benchmark.py \
    --method streaming_llm \
    --num_samples 5 \
    --max_tokens 3000 \
    --model_id /mnt/disk1/models/pythia-2.8b
```

### 3. æŸ¥çœ‹å†å²ç»“æœ

```bash
# åˆ—å‡ºæ‰€æœ‰ç»“æœç›®å½•
ls -lt results/

# æŸ¥çœ‹æœ€æ–°çš„ç»“æœ
ls -t results/ | head -1

# æŸ¥çœ‹æœ€æ–°ç»“æœçš„ JSON
cat results/$(ls -t results/ | head -1)/results.json | jq
```

---

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [BENCHMARK_UPDATES.md](./docs/BENCHMARK_UPDATES.md) - è¯¦ç»†çš„æ›´æ–°è¯´æ˜
- [STREAMINGLLM_BENCHMARK_CONFIG.md](./docs/STREAMINGLLM_BENCHMARK_CONFIG.md) - StreamingLLM é…ç½®è¯´æ˜
- [README.md](./README.md) - é¡¹ç›®æ€»ä½“è¯´æ˜

---

*å¿«é€Ÿå‚è€ƒæŒ‡å—*
*ç‰ˆæœ¬: v1.1*
*æ›´æ–°æ—¥æœŸ: 2024-12-30*

